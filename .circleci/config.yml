version: 2.1

defaults: &defaults
  docker:
    - image: google/cloud-sdk:latest
  working_directory: ~/atac-seq-pipeline

machine_defaults: &machine_defaults
  machine: 
    image: circleci/classic:201808-01
  working_directory: ~/atac-seq-pipeline

make_tag: &make_tag
  name: make docker image tag
  command: |
    echo "export TAG=encodedcc/atac-seq-pipeline:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}" >> ${BASH_ENV}

commands:
  download_task_test_data:
    description: "Download task test data. This is based on py2 so run this before installing py3."
    steps:
      - run:
          command: |
            cd dev/test/test_task/
            rm -rf atac-seq-pipeline-test-data
            export BOTO_CONFIG=/dev/null
            gsutil -m cp -r gs://encode-pipeline-test-samples/encode-atac-seq-pipeline/atac-seq-pipeline-test-data .
            ./download_hg38_fasta_for_test_ataqc.sh

  gcloud_auth_service_account_py2:
    description: "Activate service account. This is based on py2 so run this before installing py3."
    steps:      
      - run:
          command: |
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            gcloud auth activate-service-account --key-file tmp_secret_key.json
            rm -f tmp_secret_key.json

  install_python3_caper_gcs:
    description: "Install py3, caper and gcs. Set py3 as default python."
    steps:      
      - run:
          command: |
            pyenv global 3.7.0
            pip install --upgrade pip
            pip install caper google-cloud-storage

jobs:
  build:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run:
          name: build image
          command: |
            source ${BASH_ENV}
            export DOCKER_CACHE_TAG=v1.7.1
            echo "pulling ${DOCKER_CACHE_TAG}!"
            docker pull encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG}
            docker login -u=${DOCKERHUB_USER} -p=${DOCKERHUB_PASS}
            docker build --cache-from encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG} --build-arg GIT_COMMIT_HASH=${CIRCLE_SHA1} --build-arg BRANCH=${CIRCLE_BRANCH} --build-arg BUILD_TAG=${TAG} -t $TAG -f dev/docker_image/Dockerfile .
            docker push ${TAG}
            docker logout
  test_tasks:
    <<: *machine_defaults
    steps:
      - checkout
      - download_task_test_data
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}
            cd dev/test/test_task/

            for wdl in test_*.wdl
            do
              prefix=${wdl%.*}
              json=${prefix}.json
              metadata=${prefix}.metadata.json
              caper run ${wdl} -i ${json} -m ${metadata} --docker ${TAG}
              if [[ "${wdl}" != "test_choose_ctl.wdl" ]]; then
                res=$(jq '.outputs["'${prefix}'.compare_md5sum.match_overall"]' "${metadata}")
                [[ "$res" == false ]] && exit 1
              fi
              rm -f ${metadata}
            done

  test_workflow_se:
    <<: *machine_defaults
    steps:
      - checkout
      - gcloud_auth_service_account_py2
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            INPUT=ENCSR889WQX_subsampled.json

            cd dev/test/test_workflow/
            source ${BASH_ENV}
            # tmp_secret_key.json is hard-coded in backend_gcp_service_account
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            caper run ../../../atac.wdl \
              --backend gcp --gcp-prj ${GOOGLE_PROJECT_ID} \
              --backend-file backend_gcp_service_account.conf \
              --out-gcs-bucket ${CAPER_OUT_DIR} --tmp-gcs-bucket ${CAPER_TMP_DIR} \
              -i ${INPUT} -m metadata.json --docker ${TAG}

            res=$(jq '.outputs["atac.qc_json_ref_match"]' metadata.json)
            [[ "$res" == false ]] && exit 1

  test_workflow_unrep_se:
    <<: *machine_defaults
    steps:
      - checkout
      - gcloud_auth_service_account_py2
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            INPUT=ENCSR889WQX_subsampled_unrep.json

            cd dev/test/test_workflow/
            source ${BASH_ENV}
            # tmp_secret_key.json is hard-coded in backend_gcp_service_account
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            caper run ../../../atac.wdl \
              --backend gcp --gcp-prj ${GOOGLE_PROJECT_ID} \
              --backend-file backend_gcp_service_account.conf \
              --out-gcs-bucket ${CAPER_OUT_DIR} --tmp-gcs-bucket ${CAPER_TMP_DIR} \
              -i ${INPUT} -m metadata.json --docker ${TAG}

            res=$(jq '.outputs["atac.qc_json_ref_match"]' metadata.json)
            [[ "$res" == false ]] && exit 1

  test_workflow_pe:
    <<: *machine_defaults
    steps:
      - checkout
      - gcloud_auth_service_account_py2
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            INPUT=ENCSR356KRQ_subsampled.json

            cd dev/test/test_workflow/
            source ${BASH_ENV}
            # tmp_secret_key.json is hard-coded in backend_gcp_service_account
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            caper run ../../../atac.wdl \
              --backend gcp --gcp-prj ${GOOGLE_PROJECT_ID} \
              --backend-file backend_gcp_service_account.conf \
              --out-gcs-bucket ${CAPER_OUT_DIR} --tmp-gcs-bucket ${CAPER_TMP_DIR} \
              -i ${INPUT} -m metadata.json --docker ${TAG}

            res=$(jq '.outputs["atac.qc_json_ref_match"]' metadata.json)
            [[ "$res" == false ]] && exit 1

  test_workflow_pe_start_from_bam:
    <<: *machine_defaults
    steps:
      - checkout
      - gcloud_auth_service_account_py2
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            INPUT=ENCSR356KRQ_subsampled_start_from_bam.json

            cd dev/test/test_workflow/
            source ${BASH_ENV}
            # tmp_secret_key.json is hard-coded in backend_gcp_service_account
            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            caper run ../../../atac.wdl \
              --backend gcp --gcp-prj ${GOOGLE_PROJECT_ID} \
              --backend-file backend_gcp_service_account.conf \
              --out-gcs-bucket ${CAPER_OUT_DIR} --tmp-gcs-bucket ${CAPER_TMP_DIR} \
              -i ${INPUT} -m metadata.json --docker ${TAG}

            res=$(jq '.outputs["atac.qc_json_ref_match"]' metadata.json)
            [[ "$res" == false ]] && exit 1

workflows:
  version: 2.1
  build_workflow:
    jobs:
      - build
      #- test_tasks:
      #    requires:
      #      - build
      #- test_workflow_se:
      #    requires:
      #      - build
      - test_workflow_unrep_se:
          requires:
            - build
      #- test_workflow_pe:
      #    requires:
      #      - build
      #- test_workflow_pe_start_from_bam:
      #    requires:
      #      - build
