version: 2.1

defaults: &defaults
  docker:
    - image: google/cloud-sdk:latest
  working_directory: ~/atac-seq-pipeline

machine_defaults: &machine_defaults
  machine: 
    image: ubuntu-1604:202007-01
  working_directory: ~/atac-seq-pipeline

make_tag: &make_tag
  name: make docker image tag
  command: |
    echo "export TAG=encodedcc/atac-seq-pipeline:${CIRCLE_BRANCH}_${CIRCLE_WORKFLOW_ID}" > ${BASH_ENV}

commands:
  download_task_test_data:
    description: "Download task test data. This is based on py2 so run this before installing py3."
    steps:
      - run:
          command: |
            cd dev/test/test_task/
            rm -rf atac-seq-pipeline-test-data
            export BOTO_CONFIG=/dev/null
            gsutil -m cp -r gs://encode-pipeline-test-samples/encode-atac-seq-pipeline/atac-seq-pipeline-test-data .
            ./download_hg38_fasta_for_test_ataqc.sh


  install_python3_caper_gcs:
    description: "Install py3, caper and gcs. Set py3 as default python."
    steps:      
      - run:
          command: |
            sudo apt-get update && sudo apt-get install software-properties-common git wget curl default-jre -y
            sudo add-apt-repository ppa:deadsnakes/ppa -y
            sudo apt-get update && sudo apt-get install python3.6 -y
            sudo wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py
            sudo python3.6 get-pip.py
            sudo ln -s /usr/bin/python3.6 /usr/local/bin/python3
            pip3 install --upgrade pip
            pip3 install caper google-cloud-storage

  run_workflow_test:
    description: "Run workflow test. This requires an env var INPUT as input JSON's basename."
    steps:
      - run:
          no_output_timeout: 300m
          command: |
            cd dev/test/test_workflow/
            source ${BASH_ENV}

            echo ${GCLOUD_SERVICE_ACCOUNT_SECRET_JSON} > tmp_secret_key.json
            export GOOGLE_APPLICATION_CREDENTIALS=$PWD/tmp_secret_key.json
            caper run ../../../atac.wdl \
              --backend gcp --gcp-prj ${GOOGLE_PROJECT_ID} \
              --gcp-service-account-key-json $PWD/tmp_secret_key.json \
              --out-gcs-bucket ${CAPER_OUT_DIR} --tmp-gcs-bucket ${CAPER_TMP_DIR} \
              -i ${INPUT} -m metadata.json --docker ${TAG}

            res=$(jq '.outputs["atac.qc_json_ref_match"]' metadata.json)
            [[ "$res" != true ]] && exit 100
            rm -f metadata.json

jobs:
  build:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - run: *make_tag
      - run:
          name: build image
          command: |
            source ${BASH_ENV}
            export DOCKER_CACHE_TAG=v1.7.1
            echo "pulling ${DOCKER_CACHE_TAG}!"
            docker pull encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG}
            docker login -u=${DOCKERHUB_USER} -p=${DOCKERHUB_PASS}
            docker build --cache-from encodedcc/atac-seq-pipeline:${DOCKER_CACHE_TAG} --build-arg GIT_COMMIT_HASH=${CIRCLE_SHA1} --build-arg BRANCH=${CIRCLE_BRANCH} --build-arg BUILD_TAG=${TAG} -t $TAG -f dev/docker_image/Dockerfile .
            docker push ${TAG}
            docker logout
  test_tasks:
    <<: *machine_defaults
    steps:
      - checkout
      - download_task_test_data
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          no_output_timeout: 300m
          command: |
            source ${BASH_ENV}
            cd dev/test/test_task/

            for wdl in test_*.wdl
            do
              prefix=${wdl%.*}
              input=${prefix}.json
              metadata=${prefix}.metadata.json
              caper run ${wdl} -i ${input} -m ${metadata} --docker ${TAG}
              if [[ "${wdl}" != "test_choose_ctl.wdl" ]]; then
                echo "Validating outputs of ${prefix}"
                res=$(jq '.outputs["'${prefix}'.compare_md5sum.match_overall"]' "${metadata}")
                [[ "$res" != true ]] && exit 100
              fi
              rm -f ${metadata}
            done

  test_workflow_se:
    <<: *machine_defaults
    steps:
      - checkout
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          command: |
            echo "export INPUT=ENCSR889WQX_subsampled.json" >> ${BASH_ENV}
      - run_workflow_test


  test_workflow_unrep_se:
    <<: *machine_defaults
    steps:
      - checkout
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          command: |
            echo "export INPUT=ENCSR889WQX_subsampled_unrep.json" >> ${BASH_ENV}
      - run_workflow_test

  test_workflow_pe:
    <<: *machine_defaults
    steps:
      - checkout
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          command: |
            echo "export INPUT=ENCSR356KRQ_subsampled.json" >> ${BASH_ENV}
      - run_workflow_test

  test_workflow_pe_start_from_bam:
    <<: *machine_defaults
    steps:
      - checkout
      - install_python3_caper_gcs
      - run: *make_tag
      - run:
          command: |
            echo "export INPUT=ENCSR356KRQ_subsampled_start_from_bam.json" >> ${BASH_ENV}
      - run_workflow_test

workflows:
  version: 2.1
  build_workflow:
    jobs:
      - build
      - test_tasks:
         requires:
           - build
      - test_workflow_se:
         requires:
           - build
      - test_workflow_unrep_se:
          requires:
            - build
      - test_workflow_pe:
         requires:
           - build
      - test_workflow_pe_start_from_bam:
         requires:
           - build
