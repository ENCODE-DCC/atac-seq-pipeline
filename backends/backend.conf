include required(classpath("application"))

backend {
  default = "Local"
  providers {

    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        concurrent-job-limit = 10
      }
    }

    sge {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
        String sge_pe = "shm"
        Int cpu = 1
        Int? time
        Int? memory_mb
        String? sge_queue
        """
        submit = """
        qsub \
        -terse \
        -V \
        -b n \
        -N ${job_name} \
        -wd ${cwd} \
        -o ${out} \
        -e ${err} \
        ${if cpu>1 then "-pe " + sge_pe + " " + cpu else " "} \
        ${"-l h_vmem=" + memory_mb/cpu + "m"} \
        ${"-l s_vmem=" + memory_mb/cpu + "m"} \
        ${"-l h_rt=" + time*3600} \
        ${"-l s_rt=" + time*3600} \
        ${"-q " + sge_queue} \
        ${script}
        """
        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }

    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30"
        concurrent-job-limit = 50        
        runtime-attributes = """
        Int cpu = 1
        Int? time
        Int? memory_mb
        String? slurm_partition
        String? slurm_account
        """
        submit = """
        sbatch \
        --export=ALL \
        -J ${job_name} \
        -D ${cwd} \
        -o ${out} \
        -e ${err} \
        ${"-t " + time*60} \
        -n 1 \
        --ntasks-per-node=1 \
        ${"--cpus-per-task=" + cpu} \
        ${"--mem=" + memory_mb} \
        ${"-p " + slurm_partition} \
        ${"--account " + slurm_account} \
        --wrap "/bin/bash ${script}"
        """
        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }

    google {
      actor-factory = "cromwell.backend.impl.jes.JesBackendLifecycleActorFactory"
      config {
        # Google project
        project = "your-project-name"
    
        # Base bucket for workflow executions
        root = "gs://your-bucket-name"

        concurrent-job-limit = 1000
        genomics-api-queries-per-100-seconds = 1000
        maximum-polling-interval = 600

        genomics {
          auth = "application-default"
          compute-service-account = "default"
          endpoint-url = "https://genomics.googleapis.com/"
          restrict-metadata-access = false
        }

        filesystems {
          gcs {
            auth = "application-default"
          }
        }
      }
    }
  }
}

services {
  LoadController {
    class = "cromwell.services.loadcontroller.impl.LoadControllerServiceActor"
    config {      
      # disable it (for login nodes on Stanford SCG, Sherlock)
      control-frequency = 21474834 seconds
    }
  }
}

system {
  abort-jobs-on-terminate = true
  graceful-server-shutdown = true
}

call-caching {
  enabled = false
  invalidate-bad-cache-results = true
}

google {
  application-name = "cromwell"
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    }
  ]
}
